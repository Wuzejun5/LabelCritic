## Branch for testing baseline models

### Baseline models
We have tested the 2D Large Vision Lanaguage Models (LVLMs) LLaVA and LLaVA-Med, and the 3D LVLM M3D. The details of the models are as follows:

#### (1) LLaVA
- Version: LLaVA-v1.6-mistral
- Local path: `/mnt/sdh/qwu59/ckpts/llava-v1.6-mistral-7b-hf`
- Download link: <a href="https://huggingface.co/llava-hf/llava-v1.6-mistral-7b-hf">
    <img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="Hugging Face" width="20"/>
</a>

#### (2) LLaVA-Med
- Version: LLaVA-Med-v1.5
- Local path: `/mnt/sdh/qwu59/ckpts/llava-med-v1.5-mistral-7b`
- Download link: <a href="https://huggingface.co/microsoft/llava-med-v1.5-mistral-7b">
    <img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="Hugging Face" width="20"/>
</a> 

#### (3) M3D
- Version: M3D-Phi3-4B
- Local Path: `/mnt/sdh/qwu59/ckpts/m3d`
- Download link: <a href="https://huggingface.co/GoodBaiBai88/M3D-LaMed-Phi-3-4B">
    <img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="Hugging Face" width="20"/>
</a>
